

### 线程

#### threading模块

t1=threading.Thread(target=func_name,(func_arg1,) 

t2=threading.Thread(target=func_name,(func_arg1,) 

t1.start()

t2.start()

t1.join() #等待线程执行完毕

t2.join()#等待线程执行完毕



```python
import threading
import time

def dance():
    print("跳舞")
    time.sleep(1)

def sing():
    print("唱歌")
    time.sleep(1)


def main():
    
    t1=threading.Thread(target=dance) 
    
    t2=threading.Thread(target=sing) 

    print(threading.enumerate())  # 打印当前线程
    t1.start()
    print(threading.enumerate()) # 打印当前线程
    t2.start()
    print(threading.enumerate()) # 打印当前线程


if __name__=='__main__':
    main()
```

##### 锁

线程资源共享，当存在多个线程对全局变量操作，存在同时操作，最终结果会产生误差。

需要使用互斥锁，防止多个函数同时操作全局变量。

mutex=threading.Lock()

x=1
def func1(n):
    global x
    mutex.acquire() #操作x时，加锁
    for i in range(n):
        x=x+1
    print('func1,x=',x)
    mutex.release()  #操作结束后，释放锁 





```python
import threading
import time

mutex=threading.Lock()

x=1
def func1(n):
    global x
    mutex.acquire()
    for i in range(n):
        x=x+1
    print('func1,x=',x)
    mutex.release()

def func2(n):
    global x
    mutex.acquire()
    for i in range(n):
        x=x+1
    print('func2,x=',x)
    mutex.release()



def main():
    
    t1=threading.Thread(target=func1,args=(1000000,))
    t2=threading.Thread(target=func2,args=(1000000,))

    t1.start()

    t2.start()

if __name__=='__main__':
    main()

```

##### 死锁

一个线程请求了锁，另一个线程也请求锁



##### 作业

###### 	多线程聊天器

```python
import socket
import threading
def recv_msg(udp_socket):
    while True:
        recv_data= udp_socket.recvfrom(1024)
        recvmsg= recv_data[0].decode('gbk')
        from_address=str(recv_data[1])
        print(f"\n 接收到来自 {from_address} 的消息: {recvmsg}\n")

def send_msg(udp_socket,address):
    while True:
        send_data=input('输入发送的数据:').encode('gbk')
        udp_socket.sendto(send_data,address)

def main():
    udp_socket=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)
    udp_socket.bind(('127.0.0.1',30001))
    ip=input('输入ip:')
    port=int(input('输入port:'))
    address=(ip,port)
    
    t1=threading.Thread(target=send_msg,args=(udp_socket,address))
    t2=threading.Thread(target=recv_msg,args=(udp_socket,))
    t1.start()
    t2.start()
if __name__=="__main__":
    main()
```



解2 无交互发送接收

```python
import multiprocessing
import socket
def send_msg():
    udp_socket=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)
    local_address=('127.0.0.1',2400)
    udp_socket.bind(local_address)
    udp_socket.sendto('你好'.encode('gbk'),('127.0.0.1',2399))  
    print('已发送消息\n')
    udp_socket.close()

def recv_msg():
    udp_socket=socket.socket(socket.AF_INET,socket.SOCK_DGRAM)
    local_address=('127.0.0.1',2399)
    udp_socket.bind(local_address)
    data=udp_socket.recvfrom(1024)
    #print("接收消息:",data.decode('gbk'))
    print("接收消息:",data[0].decode('gbk'),"来源:",str(data[1]))
    udp_socket.close()

def main():
    send=multiprocessing.Process(target=send_msg)
    recv=multiprocessing.Process(target=recv_msg)
    send.start()
    recv.start()


if __name__ == '__main__':
    main()
```



### 进程

程序：未运行的可执行代码或文件

进程：一个程序运行后，程序加上占用的资源称之为进程，它是操作系统分配资源的基本单位

多任务可以用进程方式完成



#### 进程的状态

任务数大于cpu的核数，有一些任务正在执行，有些任务在等待cpu执行，任务有不同的状态。

新建启动

就绪态：运行的条件已经具备，正在等待cpu执行

执行态：cpu正在执行其功能

等待态：等待某些条件满足，如sleep，处于等待态



运用场景：进程适合密集型运算场景，线程适合IO网络任务场景

#### multiprocessing模块

os.getpid() 获取当前任务的进程号

os.getpid() 获取父进程的进程号

p=multiprocessing.Process(target=test)  创建进程示例p，进程运行test函数。

p.start()  启动进程

kill -9  程序进程号    关闭进程 

##### 创建无参进程

```python
import os
import time
import multiprocessing

def test():
    while True:
        print('in 子进程 pid=%d  ,父进程 pid=%d' %(os.getpid(),os.getppid()))
        time.sleep(1)

def main():
    print('主进程 pid=%d  ,父进程 pid=%d' %(os.getpid(),os.getppid()))
    p = multiprocessing.Process(target=test)
    p.start()

if __name__=='__main__':
    main()
```



##### 进程传参



```python
import os
import time
import multiprocessing

def test(a,b,c,*args,**kwargs):
    print(a)
    print(b)
    print(c)
    print(args)
    print(kwargs)

def main():
    
    p = multiprocessing.Process(target=test,args=(11,22,33,44,55),kwargs={'name':'test'})
    p.start()

if __name__=='__main__':
    main()

'''
运行结果：
11
22
33
(44, 55)
{'name': 'test'}
'''
```

##### 多进程之间不共享全局变量

```python
import os
import time
import multiprocessing

nums=[11,22,33]
def test1():
    nums.append(44)
    print(f'进程1中 nums={nums}')
    time.sleep(3)

def test2():
    nums.append(44)
    print(f'进程2中 nums={nums}')
    time.sleep(3)

def main():
    p1=multiprocessing.Process(target=test1)
    p2=multiprocessing.Process(target=test1)
    p1.start()
    p2.start()

if __name__=="__main__":
    main()

'''
进程1中 nums=[11, 22, 33, 44]
进程1中 nums=[11, 22, 33, 44]
进程直接不共享全局变量
'''
```



进程是分配资源的最小单位，可以分配内存磁盘等资源，线程是由进程创建的，因此一个进程中的线程是在一个内存中的，资源共享。

进程之间资源不共享

##### 多进程之间通过Queue()实现数据共享

```python
#data模拟数据，download函数将data保存到队列q，analysis函数将q中数据保存到watting_analysis_data列表中。
#下载和分析同步执行的，multiprocessing.Queue()是进程共享的，使用Queue()作为两个进程的共享变量。
import multiprocessing 


def download_from_web(q):
    data = [1,2,3,4,5]  #模拟数据
    for i in data:
        q.put(i)
    print('下载器下载完成并成功写入数据到队列')

#multiprocessing.Queue.qsize
def analysis_data(q):
    watting_analysis_data = list()
    while True:
        
        data=q.get()
        watting_analysis_data.append(data)
        if q.empty():
            break
    print(watting_analysis_data)

def main():
    q=multiprocessing.Queue()
    p1=multiprocessing.Process(target=download_from_web,args=(q,))
    p2=multiprocessing.Process(target=analysis_data,args=(q,))
    p1.start()
    p2.start()
if __name__=="__main__":
    main()

```



##### 进程池 Pool

Pool.apply('函数名',(参数1,))

Pool.close() 添加进程结束，关闭进程池

Pool.start()  启动进程

Pool.join() 等待进程执行完毕

```python
import os
import multiprocessing 
from multiprocessing import Pool  
from random import random
import time
import random

def  work(i):
    t1=time.time()
    print('work  %d 启动， pid %d' %(i,os.getpid()))
    time.sleep((random.random() *5))
    t2=time.time()
    print('work  %d 运行完成， 耗时 %d' %(i,(t2-t1)))
def main():
    po=Pool(3)
    for i in range(0,10):
        po.apply(work,(i,))
    po.close()
    print('进程开始启动')
    po.join()
    print('进程执行完毕')


if __name__ == '__main__':
    main()

```

进程数不能太多，内存容易爆



##### 作业：文件夹复制器

```python
'''
队列中使用相对路径，判断和创建使用绝对路径
'''

import multiprocessing
import os
from multiprocessing import Queue
from multiprocessing import Pool


file_queue=multiprocessing.Queue()
cwd=os.getcwd()
print(cwd)

save_dir=os.path.join(cwd,'save_dir')


file_list=[]


def do_path(path):
    real_path=os.path.join(cwd,path) #目录绝对路径
    
    for i in os.listdir(real_path):
        #print(i)
        pass

    for i in os.listdir(real_path):
        #每个文件路径
        full_path=os.path.join(os.path.join(real_path,i))

        # 文件不是目录
        if not os.path.isdir(full_path):
            f_path=os.path.join(path,i)
            #加入到队列
            file_list.append(f_path)

        # 文件是目录
        else:            

            #发现目录
            print('-'*50)
            print('发现目录',full_path)
            print('-'*50)
            #

            #获得目录相对路径
            path_1=os.path.join(path,i)
            file_list.append(path_1)
            print('递归调用do_path(%s)' %(path_1))
            do_path(path_1)

def copy_file(src,dest):
    #去除路径前面的 多任务\
    src_1=src.split('\\')[1:]
    src_1='\\'.join(src_1)
    #print('保存的相对路径',src_1)

    file_save_path=os.path.join(cwd,dest,src_1)
    print('保存路径',file_save_path)
    print('处理目标文件或目录',file_save_path)
    #目录复制
    #原位置路径
    file_src=os.path.join(cwd,src)
    if os.path.isdir(file_src):
        print('-'*50)
        print('发现目录',file_save_path)
        print('-'*50)
        if not os.path.exists(file_save_path):
            #print('保存目录',file_save_path,'不存在')
            os.makedirs(file_save_path)
            #print('保存目录',file_save_path,'创建')
    #文件复制
    else:
        file_dir=os.path.dirname(file_save_path)
        if os.path.exists(file_dir):
            #print('文件夹已存在')
            pass
        else:
            os.makedirs(file_dir)
            #print('文件夹%s已创建' %file_dir)
        with open(os.path.join(cwd,src),'rb') as f:

            with open(file_save_path,'wb') as sf:
                sf.write(f.read()) 

def main():
    #C:\\Users\\lb\\Desktop\\python\\预科班2\\多任务\\download\\dir1
    #os.makedirs("C:\\Users\\lb\\Desktop\\python\\预科班2\\多任务\\download\\acc1")
    do_path('多任务\download')
    print(file_list)
    for i in file_list:
        print(i,'加入队列file_queue')
        file_queue.put(i)

    
    save_dir='save_dir'
    po=Pool(3)
    while not file_queue.empty():
        file=file_queue.get()
        po.apply(copy_file,(file,save_dir,))
    po.close()
    po.join()
    

if __name__=='__main__':
    main()
```



### 协程



#### 实现一个可迭代的对象

类中定义\_\_iter\_\_()   , \_\_next\_\_()

isinstance(对象,Iterable)  判断对象是否是可迭代对象

```python
from collections.abc import Iterable


class Students:
    def __init__(self):
        self.names = list()
        self.current=0
    def __iter__(self):
        return self
    def __next__(self):
        if self.current < len(self.names) :
            ret= self.names[self.current]
            self.current += 1
            return ret
        else:
            raise StopIteration
    def add(self,name):
        self.names.append(name)
def main():
    s=Students()
    s.add('zs')
    s.add('ls')
    s.add('ww')
    print(isinstance(s,Iterable))

    for item in s.names:
        print(item)
if __name__ == '__main__':
    main()
```



#### yield生成器

函数中加了yield，变成了生成器

```
def create_num(all_num):
    a,b=0,1
    current=0
    while current <all_num:
        yield a
        a,b=b,a+b
        current+=1
    return 'ok'
    
    
obj=create_num(10)

while True:
    try:
        ret=next(obj)
        print(ret)
    except StopIteration as e:
        print(e.value)
        break
```



#### 使用yield实现多任务

使用yield后，处于等待，切换到本次循环外一层

```
import time

def task_1():
    while True:
        print('1')
        time.sleep(0.5)
        yield

def task_2():
    while True:
        print('2')
        time.sleep(0.5)
        yield

def main():
    t1=task_1()
    t2=task_2()
    while True:
        next(t1)
        next(t2)
if __name__ == '__main__':
    main()
```

#### 协程介绍

协程是python中另外一种实现多任务的方式，比线程更小，占用更小执行单元。 自带CPU上下文，保存或恢复 CPU上下文就可以切换回之前暂停的协程 

#### 协程和线程比较

线程消耗性能，协程相对不耗性能

协程的切换只需要保存和恢复CPU的上下文。

线程切换需要保存和恢复 CPU上下文、缓存Cache等等数据，因为线程有缓存Cache等数据。

#### greenlet 实现多任务

greenle.switch() 切换函数

```python
from greenlet import greenlet 
import time


def test1():
    while True:
        print('1')
        g2.switch()
        time.sleep(0.1)

def test2():
    while True:
        print('2')
        g1.switch()
        time.sleep(0.1)


if __name__=='__main__':
    g1=greenlet(test1)
    g2=greenlet(test2)
    g1.switch()
```



#### gevent



gevent.spawn(函数，参数) 创建协程

.join() 函数启动协程



使用time.sleep()等有等待阻塞时，使用monkey.patch_all() 才可以实现任务异步执行



```python
import time
import gevent

from gevent import monkey
monkey.patch_all()

def f1(n):
    for i in range(n):
        print(gevent.getcurrent(),i)
        time.sleep(2)

g1=gevent.spawn(f1,5)
g2=gevent.spawn(f1,3)

g1.join()
g2.join()


```



或者使用gevent自带的sleep()

例外的，如socket模块中使用tcp、udp的accept()方法，gevent中没有替换的方法，只能使用monkey.patch_all()

```python
import time
import gevent

#from gevent import monkey
#monkey.patch_all() #使用gevent.sleep(1)，不用执行monkey.patch_all()

def f1(n):
    for i in range(n):
        print(gevent.getcurrent(),i)
        gevent.sleep(1) #gevent模块函数sleep()
        #time.sleep(2)

g1=gevent.spawn(f1,5)
g2=gevent.spawn(f1,3)

g1.join()
g2.join()

```



只要是协程，都会用到生成器，暂停保存当前状态的特点，

切换任务之后回来执行原本任务需要在之前执行的基础之上继续执行



#### 作业：协程分配下载文件

```python
import gevent
from gevent import monkey
monkey.patch_all()
import os
import requests
from queue import Queue
import time

#装饰器
def code_time(func):
    def new_func(url,fp_num,save_path):  
        t1=time.time()
        func(url,fp_num,save_path)
        t2=time.time()
        print('耗时：',(t2-t1))
    return new_func


url='http://down.sandai.net/thunderx/XunLeiWebSetup_yxw.exe'


@code_time
def download(url,save_name):
    r= requests.get(url,stream=True)
    #print(r.status_code)
    with open(save_name,mode='wb') as f:
        for chunk in r.iter_content(chunk_size=32):
            f.write(chunk)

def get_download_range(file_length,fp_nums):
    fp_queue=Queue(fp_nums)
    start_bytes=0
    #获得分段长度
    trunk=file_length//fp_nums
    for i in range(fp_nums):
        bytes_cur=start_bytes+trunk

        if i==fp_nums-1:
            file_range=[start_bytes,file_length-1]
        else:
            file_range=[start_bytes,start_bytes+trunk]
        
        fp_queue.put(file_range)
        start_bytes=bytes_cur+1
    return fp_queue

@code_time
def download_one(url,range,save_name):
    header={"Range":f"bytes={range[0]}-{range[1]}"}
    print('下载字节范围：',f"bytes={range[0]}-{range[1]}")    
    r=requests.get(url,headers=header,stream=True)
    with open(save_name,mode='rb+') as f:
        f.seek(range[0])
        for chunk in r.iter_content(chunk_size=32):
            f.write(chunk)

@code_time
def download_fp(url,fp_nums,save_name):

    r= requests.head(url,stream=True)
    if r.status_code == 200:
        print('ok')
    else:
        return 'error'

    file_length=int(r.headers['Content-Length'])
    print(type(file_length))
    print('文件长度：',r.headers['Content-Length'])

    range_queue=get_download_range(file_length,fp_nums)
    # 创建空文件
    with open(save_name,mode='wb') as f:
        pass
    #分段获取
    jobs=[]
    while not range_queue.empty():
        range=range_queue.get()
        jobs.append(gevent.spawn(download_one,url,range,save_name))
    gevent.joinall(jobs)
    


def main():

    download_fp(url,10,'xl1.exe')

if __name__ == '__main__':
    main()
```

